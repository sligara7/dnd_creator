# Environment Variables Template
# Copy this to .env and fill in your values

# Database Configuration
DB_PASSWORD=your_secure_database_password_here

# LLM Provider Configuration
LLM_PROVIDER=openai
# For OpenAI
OPENAI_API_KEY=your-openai-api-key-here
# For Anthropic  
ANTHROPIC_API_KEY=your-anthropic-api-key-here
# Model to use (updated for GPT-4.1-nano)
LLM_MODEL=gpt-4.1-nano-2025-04-14

# Rate Limiting Configuration (strict Tier 1 limits)
# OpenAI Free Tier Limits
OPENAI_RPM=3              # Requests per minute
OPENAI_RPD=200            # Requests per day  
OPENAI_TPM=40000          # Tokens per minute

# Anthropic Rate Limits (conservative defaults)
ANTHROPIC_RPM=5           # Requests per minute
ANTHROPIC_RPD=1000        # Requests per day
ANTHROPIC_TPM=10000       # Tokens per minute

# Rate Limiting Behavior
RATE_LIMIT_MAX_RETRIES=3  # Max retry attempts
RATE_LIMIT_BASE_DELAY=1.0 # Base delay in seconds
RATE_LIMIT_MAX_DELAY=60.0 # Maximum delay in seconds

# API Security
SECRET_KEY=your-super-secret-key-for-jwt-tokens-change-this
DEBUG=false

# Logging
LOG_LEVEL=INFO

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080,https://yourdomain.com

# Optional: Custom LLM endpoint
# LLM_BASE_URL=https://api.your-llm-provider.com
# LLM_API_KEY=your-custom-api-key
